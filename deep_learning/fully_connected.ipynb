{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Goals\n",
    "- Create a feedforward neural network for classifying CIFAR10 dataset\n",
    "- Various activation functions and their pros/cons\n",
    "- Use tensor board for visualiazing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# imports and setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "writer = SummaryWriter('runs/cifar10_experiment_11')\n",
    "\n",
    "# Set random seed for pytorch and numpy\n",
    "# numpy seed takes care of numpy and scipy\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using {device} device\")\n",
    "\n",
    "# classes from CIFAR10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "def imshow(ax, img):\n",
    "    npimg = img.numpy()\n",
    "    # normalize the image from 0 to 1, cifar10 has it from -1 to 1\n",
    "    npimg = (npimg+1)/2\n",
    "    # imshow expects color channel to be the third dimension\n",
    "    # and it expects the RGB values to be between \n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def visualize_training_examples(train_dataset, classes, num_images=6):\n",
    "    # Select num_images random indices\n",
    "    indices = np.random.choice(len(train_dataset), size=num_images, replace=False)\n",
    "\n",
    "    # Show images and labels\n",
    "    # figure size should be dependent on \n",
    "    plt.figure(figsize=(8, (num_images//2)*4))\n",
    "    for i, idx in enumerate(indices):\n",
    "        ax = plt.subplot(num_images//2, 2, i + 1)\n",
    "        image, label = train_dataset[idx]\n",
    "        imshow(ax, image)\n",
    "        ax.set_title(classes[label])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_data(dataset_loc='./data',batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Adjust these values for normalization\n",
    "    ])\n",
    "\n",
    "    # Dataset class stores features and target\n",
    "    # DataLoader builds an iterator on top of Dataset class\n",
    "\n",
    "    # Load CIFAR10 dataset\n",
    "    train_dataset = datasets.CIFAR10(root=dataset_loc, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10(root=dataset_loc, train=False, download=True, transform=transform)\n",
    "\n",
    "    # Use stratified sampling to split the train dataset into train and validation\n",
    "    train_dataset, validation_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42, stratify=train_dataset.targets)\n",
    "\n",
    "    # Log some info about the dataset type and size\n",
    "    logging.info(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    logging.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "    # visualize_training_examples(train_dataset, classes, num_images=20)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 * 32 * 32, 2048)\n",
    "        self.bn1 = nn.BatchNorm1d(2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(128)\n",
    "        self.fc6 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3 * 32 * 32)  # Flatten the images\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = F.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move data to device for every iteration\n",
    "        # gpu memory is limited, so we can't move all data at once\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # zero the gradients, otherwise they will accumulate\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += accuracy.item()\n",
    "        if (batch_idx+1) % 100 == 0: # +1 so that we don't print for 0th batch\n",
    "            # Print running loss and running accuracy every 100 batches, also print fraction of epoch completed\n",
    "            logging.info(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {running_loss/100:.6f}\\tAccuracy: {running_accuracy/100:.6f}')\n",
    "            # logging.info(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {running_loss:.6f}')\n",
    "            # Log running loss to tensorboard\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * len(train_loader) + batch_idx)\n",
    "            # Log accuracy to tensorboard\n",
    "            writer.add_scalar('training accuracy', running_accuracy / 100, epoch * len(train_loader) + batch_idx)\n",
    "            # writer.add_scalar('training accuracy', accuracy, epoch * len(train_loader) + batch_idx)\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "def test(model, device, test_loader, epoch=None, validation=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # reduction='sum' means that we will get the sum of the loss instead of the mean\n",
    "            # item() gives the scalar value of the loss\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            # get the index of the max log-probability\n",
    "            # dim=1 means that we will get the max value for each row\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    if validation:\n",
    "        logging.info(f'Validation set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "        writer.add_scalar('validation loss', test_loss, epoch)\n",
    "        writer.add_scalar('validation accuracy', correct / len(test_loader.dataset), epoch)\n",
    "    else:\n",
    "        # log test loss and accuracy to tensorboard\n",
    "        logging.info(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "        writer.add_scalar('test loss', test_loss)\n",
    "        writer.add_scalar('test accuracy', correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train dataset size: 40000\n",
      "INFO:root:Test dataset size: 10000\n",
      "INFO:root:Epoch: 0 [6336/40000 (16%)]\tLoss: 1.931427\tAccuracy: 0.303750\n",
      "INFO:root:Epoch: 0 [12736/40000 (32%)]\tLoss: 1.771827\tAccuracy: 0.366406\n",
      "INFO:root:Epoch: 0 [19136/40000 (48%)]\tLoss: 1.723358\tAccuracy: 0.373437\n",
      "INFO:root:Epoch: 0 [25536/40000 (64%)]\tLoss: 1.742861\tAccuracy: 0.362344\n",
      "INFO:root:Epoch: 0 [31936/40000 (80%)]\tLoss: 1.701176\tAccuracy: 0.394219\n",
      "INFO:root:Epoch: 0 [38336/40000 (96%)]\tLoss: 1.689433\tAccuracy: 0.398281\n",
      "INFO:root:Validation set: Average loss: 1.6510, Accuracy: 4113/10000 (41%)\n",
      "INFO:root:Epoch: 1 [6336/40000 (16%)]\tLoss: 1.670840\tAccuracy: 0.398750\n",
      "INFO:root:Epoch: 1 [12736/40000 (32%)]\tLoss: 1.651841\tAccuracy: 0.410781\n",
      "INFO:root:Epoch: 1 [19136/40000 (48%)]\tLoss: 1.659517\tAccuracy: 0.406406\n",
      "INFO:root:Epoch: 1 [25536/40000 (64%)]\tLoss: 1.661509\tAccuracy: 0.402187\n",
      "INFO:root:Epoch: 1 [31936/40000 (80%)]\tLoss: 1.661809\tAccuracy: 0.409062\n",
      "INFO:root:Epoch: 1 [38336/40000 (96%)]\tLoss: 1.643589\tAccuracy: 0.406875\n",
      "INFO:root:Validation set: Average loss: 1.6778, Accuracy: 3904/10000 (39%)\n",
      "INFO:root:Epoch: 2 [6336/40000 (16%)]\tLoss: 1.618008\tAccuracy: 0.419844\n",
      "INFO:root:Epoch: 2 [12736/40000 (32%)]\tLoss: 1.621033\tAccuracy: 0.420781\n",
      "INFO:root:Epoch: 2 [19136/40000 (48%)]\tLoss: 1.630700\tAccuracy: 0.417187\n",
      "INFO:root:Epoch: 2 [25536/40000 (64%)]\tLoss: 1.600754\tAccuracy: 0.428594\n",
      "INFO:root:Epoch: 2 [31936/40000 (80%)]\tLoss: 1.607791\tAccuracy: 0.427656\n",
      "INFO:root:Epoch: 2 [38336/40000 (96%)]\tLoss: 1.584387\tAccuracy: 0.433594\n",
      "INFO:root:Validation set: Average loss: 1.5543, Accuracy: 4502/10000 (45%)\n",
      "INFO:root:Epoch: 3 [6336/40000 (16%)]\tLoss: 1.542313\tAccuracy: 0.451875\n",
      "INFO:root:Epoch: 3 [12736/40000 (32%)]\tLoss: 1.558777\tAccuracy: 0.449844\n",
      "INFO:root:Epoch: 3 [19136/40000 (48%)]\tLoss: 1.562327\tAccuracy: 0.438437\n",
      "INFO:root:Epoch: 3 [25536/40000 (64%)]\tLoss: 1.537252\tAccuracy: 0.450781\n",
      "INFO:root:Epoch: 3 [31936/40000 (80%)]\tLoss: 1.551274\tAccuracy: 0.446719\n",
      "INFO:root:Epoch: 3 [38336/40000 (96%)]\tLoss: 1.507573\tAccuracy: 0.459219\n",
      "INFO:root:Validation set: Average loss: 1.5122, Accuracy: 4590/10000 (46%)\n",
      "INFO:root:Epoch: 4 [6336/40000 (16%)]\tLoss: 1.472861\tAccuracy: 0.470938\n",
      "INFO:root:Epoch: 4 [12736/40000 (32%)]\tLoss: 1.501154\tAccuracy: 0.466250\n",
      "INFO:root:Epoch: 4 [19136/40000 (48%)]\tLoss: 1.484252\tAccuracy: 0.472813\n",
      "INFO:root:Epoch: 4 [25536/40000 (64%)]\tLoss: 1.501449\tAccuracy: 0.464687\n",
      "INFO:root:Epoch: 4 [31936/40000 (80%)]\tLoss: 1.499466\tAccuracy: 0.464062\n",
      "INFO:root:Epoch: 4 [38336/40000 (96%)]\tLoss: 1.461772\tAccuracy: 0.481406\n",
      "INFO:root:Validation set: Average loss: 1.4662, Accuracy: 4895/10000 (49%)\n",
      "INFO:root:Epoch: 5 [6336/40000 (16%)]\tLoss: 1.425874\tAccuracy: 0.486563\n",
      "INFO:root:Epoch: 5 [12736/40000 (32%)]\tLoss: 1.415554\tAccuracy: 0.498906\n",
      "INFO:root:Epoch: 5 [19136/40000 (48%)]\tLoss: 1.451940\tAccuracy: 0.476250\n",
      "INFO:root:Epoch: 5 [25536/40000 (64%)]\tLoss: 1.440353\tAccuracy: 0.484687\n",
      "INFO:root:Epoch: 5 [31936/40000 (80%)]\tLoss: 1.439335\tAccuracy: 0.493437\n",
      "INFO:root:Epoch: 5 [38336/40000 (96%)]\tLoss: 1.431339\tAccuracy: 0.490938\n",
      "INFO:root:Validation set: Average loss: 1.4404, Accuracy: 4889/10000 (49%)\n",
      "INFO:root:Epoch: 6 [6336/40000 (16%)]\tLoss: 1.390453\tAccuracy: 0.504844\n",
      "INFO:root:Epoch: 6 [12736/40000 (32%)]\tLoss: 1.407893\tAccuracy: 0.500469\n",
      "INFO:root:Epoch: 6 [19136/40000 (48%)]\tLoss: 1.398912\tAccuracy: 0.501563\n",
      "INFO:root:Epoch: 6 [25536/40000 (64%)]\tLoss: 1.408840\tAccuracy: 0.495312\n",
      "INFO:root:Epoch: 6 [31936/40000 (80%)]\tLoss: 1.410976\tAccuracy: 0.493594\n",
      "INFO:root:Epoch: 6 [38336/40000 (96%)]\tLoss: 1.399623\tAccuracy: 0.503906\n",
      "INFO:root:Validation set: Average loss: 1.4434, Accuracy: 4918/10000 (49%)\n",
      "INFO:root:Epoch: 7 [6336/40000 (16%)]\tLoss: 1.355595\tAccuracy: 0.517344\n",
      "INFO:root:Epoch: 7 [12736/40000 (32%)]\tLoss: 1.374990\tAccuracy: 0.509531\n",
      "INFO:root:Epoch: 7 [19136/40000 (48%)]\tLoss: 1.360702\tAccuracy: 0.517344\n",
      "INFO:root:Epoch: 7 [25536/40000 (64%)]\tLoss: 1.386825\tAccuracy: 0.509219\n",
      "INFO:root:Epoch: 7 [31936/40000 (80%)]\tLoss: 1.375917\tAccuracy: 0.507656\n",
      "INFO:root:Epoch: 7 [38336/40000 (96%)]\tLoss: 1.371283\tAccuracy: 0.513125\n",
      "INFO:root:Validation set: Average loss: 1.4330, Accuracy: 4927/10000 (49%)\n",
      "INFO:root:Epoch: 8 [6336/40000 (16%)]\tLoss: 1.327109\tAccuracy: 0.534375\n",
      "INFO:root:Epoch: 8 [12736/40000 (32%)]\tLoss: 1.353367\tAccuracy: 0.527969\n",
      "INFO:root:Epoch: 8 [19136/40000 (48%)]\tLoss: 1.344868\tAccuracy: 0.519687\n",
      "INFO:root:Epoch: 8 [25536/40000 (64%)]\tLoss: 1.356323\tAccuracy: 0.515938\n",
      "INFO:root:Epoch: 8 [31936/40000 (80%)]\tLoss: 1.352632\tAccuracy: 0.520781\n",
      "INFO:root:Epoch: 8 [38336/40000 (96%)]\tLoss: 1.345812\tAccuracy: 0.527969\n",
      "INFO:root:Validation set: Average loss: 1.3842, Accuracy: 5165/10000 (52%)\n",
      "INFO:root:Epoch: 9 [6336/40000 (16%)]\tLoss: 1.305792\tAccuracy: 0.544219\n",
      "INFO:root:Epoch: 9 [12736/40000 (32%)]\tLoss: 1.339551\tAccuracy: 0.525625\n",
      "INFO:root:Epoch: 9 [19136/40000 (48%)]\tLoss: 1.336251\tAccuracy: 0.522500\n",
      "INFO:root:Epoch: 9 [25536/40000 (64%)]\tLoss: 1.333606\tAccuracy: 0.534531\n",
      "INFO:root:Epoch: 9 [31936/40000 (80%)]\tLoss: 1.344306\tAccuracy: 0.523750\n",
      "INFO:root:Epoch: 9 [38336/40000 (96%)]\tLoss: 1.336239\tAccuracy: 0.529062\n",
      "INFO:root:Validation set: Average loss: 1.3931, Accuracy: 5103/10000 (51%)\n",
      "INFO:root:Epoch: 10 [6336/40000 (16%)]\tLoss: 1.273617\tAccuracy: 0.545781\n",
      "INFO:root:Epoch: 10 [12736/40000 (32%)]\tLoss: 1.317635\tAccuracy: 0.533750\n",
      "INFO:root:Epoch: 10 [19136/40000 (48%)]\tLoss: 1.322291\tAccuracy: 0.538125\n",
      "INFO:root:Epoch: 10 [25536/40000 (64%)]\tLoss: 1.319075\tAccuracy: 0.523594\n",
      "INFO:root:Epoch: 10 [31936/40000 (80%)]\tLoss: 1.314994\tAccuracy: 0.536250\n",
      "INFO:root:Epoch: 10 [38336/40000 (96%)]\tLoss: 1.320859\tAccuracy: 0.524531\n",
      "INFO:root:Validation set: Average loss: 1.3748, Accuracy: 5174/10000 (52%)\n",
      "INFO:root:Epoch: 11 [6336/40000 (16%)]\tLoss: 1.248809\tAccuracy: 0.556406\n",
      "INFO:root:Epoch: 11 [12736/40000 (32%)]\tLoss: 1.320959\tAccuracy: 0.530312\n",
      "INFO:root:Epoch: 11 [19136/40000 (48%)]\tLoss: 1.285848\tAccuracy: 0.542656\n",
      "INFO:root:Epoch: 11 [25536/40000 (64%)]\tLoss: 1.323087\tAccuracy: 0.534062\n",
      "INFO:root:Epoch: 11 [31936/40000 (80%)]\tLoss: 1.310988\tAccuracy: 0.533281\n",
      "INFO:root:Epoch: 11 [38336/40000 (96%)]\tLoss: 1.309172\tAccuracy: 0.536250\n",
      "INFO:root:Validation set: Average loss: 1.3699, Accuracy: 5165/10000 (52%)\n",
      "INFO:root:Epoch: 12 [6336/40000 (16%)]\tLoss: 1.243641\tAccuracy: 0.564688\n",
      "INFO:root:Epoch: 12 [12736/40000 (32%)]\tLoss: 1.270425\tAccuracy: 0.547188\n",
      "INFO:root:Epoch: 12 [19136/40000 (48%)]\tLoss: 1.302384\tAccuracy: 0.538125\n",
      "INFO:root:Epoch: 12 [25536/40000 (64%)]\tLoss: 1.293876\tAccuracy: 0.543906\n",
      "INFO:root:Epoch: 12 [31936/40000 (80%)]\tLoss: 1.288287\tAccuracy: 0.547500\n",
      "INFO:root:Epoch: 12 [38336/40000 (96%)]\tLoss: 1.321722\tAccuracy: 0.527188\n",
      "INFO:root:Validation set: Average loss: 1.3831, Accuracy: 5104/10000 (51%)\n",
      "INFO:root:Epoch: 13 [6336/40000 (16%)]\tLoss: 1.246120\tAccuracy: 0.550156\n",
      "INFO:root:Epoch: 13 [12736/40000 (32%)]\tLoss: 1.254657\tAccuracy: 0.550625\n",
      "INFO:root:Epoch: 13 [19136/40000 (48%)]\tLoss: 1.265248\tAccuracy: 0.550312\n",
      "INFO:root:Epoch: 13 [25536/40000 (64%)]\tLoss: 1.256513\tAccuracy: 0.555937\n",
      "INFO:root:Epoch: 13 [31936/40000 (80%)]\tLoss: 1.294869\tAccuracy: 0.539375\n",
      "INFO:root:Epoch: 13 [38336/40000 (96%)]\tLoss: 1.298629\tAccuracy: 0.538125\n",
      "INFO:root:Validation set: Average loss: 1.3809, Accuracy: 5135/10000 (51%)\n",
      "INFO:root:Epoch: 14 [6336/40000 (16%)]\tLoss: 1.238866\tAccuracy: 0.567500\n",
      "INFO:root:Epoch: 14 [12736/40000 (32%)]\tLoss: 1.230158\tAccuracy: 0.558438\n",
      "INFO:root:Epoch: 14 [19136/40000 (48%)]\tLoss: 1.267220\tAccuracy: 0.560469\n",
      "INFO:root:Epoch: 14 [25536/40000 (64%)]\tLoss: 1.267309\tAccuracy: 0.548281\n",
      "INFO:root:Epoch: 14 [31936/40000 (80%)]\tLoss: 1.280352\tAccuracy: 0.546406\n",
      "INFO:root:Epoch: 14 [38336/40000 (96%)]\tLoss: 1.261739\tAccuracy: 0.551562\n",
      "INFO:root:Validation set: Average loss: 1.3663, Accuracy: 5250/10000 (52%)\n",
      "INFO:root:Epoch: 15 [6336/40000 (16%)]\tLoss: 1.210486\tAccuracy: 0.567187\n",
      "INFO:root:Epoch: 15 [12736/40000 (32%)]\tLoss: 1.249719\tAccuracy: 0.557187\n",
      "INFO:root:Epoch: 15 [19136/40000 (48%)]\tLoss: 1.256289\tAccuracy: 0.558125\n",
      "INFO:root:Epoch: 15 [25536/40000 (64%)]\tLoss: 1.271170\tAccuracy: 0.547969\n",
      "INFO:root:Epoch: 15 [31936/40000 (80%)]\tLoss: 1.262549\tAccuracy: 0.552500\n",
      "INFO:root:Epoch: 15 [38336/40000 (96%)]\tLoss: 1.281480\tAccuracy: 0.546719\n",
      "INFO:root:Validation set: Average loss: 1.3978, Accuracy: 5095/10000 (51%)\n",
      "INFO:root:Epoch: 16 [6336/40000 (16%)]\tLoss: 1.201075\tAccuracy: 0.580000\n",
      "INFO:root:Epoch: 16 [12736/40000 (32%)]\tLoss: 1.237245\tAccuracy: 0.567969\n",
      "INFO:root:Epoch: 16 [19136/40000 (48%)]\tLoss: 1.245606\tAccuracy: 0.554531\n",
      "INFO:root:Epoch: 16 [25536/40000 (64%)]\tLoss: 1.269585\tAccuracy: 0.547656\n",
      "INFO:root:Epoch: 16 [31936/40000 (80%)]\tLoss: 1.269589\tAccuracy: 0.547500\n",
      "INFO:root:Epoch: 16 [38336/40000 (96%)]\tLoss: 1.253645\tAccuracy: 0.556406\n",
      "INFO:root:Validation set: Average loss: 1.3791, Accuracy: 5124/10000 (51%)\n",
      "INFO:root:Epoch: 17 [6336/40000 (16%)]\tLoss: 1.200186\tAccuracy: 0.572344\n",
      "INFO:root:Epoch: 17 [12736/40000 (32%)]\tLoss: 1.230798\tAccuracy: 0.572031\n",
      "INFO:root:Epoch: 17 [19136/40000 (48%)]\tLoss: 1.232102\tAccuracy: 0.558750\n",
      "INFO:root:Epoch: 17 [25536/40000 (64%)]\tLoss: 1.245892\tAccuracy: 0.561875\n",
      "INFO:root:Epoch: 17 [31936/40000 (80%)]\tLoss: 1.262907\tAccuracy: 0.548750\n",
      "INFO:root:Epoch: 17 [38336/40000 (96%)]\tLoss: 1.256847\tAccuracy: 0.556562\n",
      "INFO:root:Validation set: Average loss: 1.3460, Accuracy: 5281/10000 (53%)\n",
      "INFO:root:Epoch: 18 [6336/40000 (16%)]\tLoss: 1.198666\tAccuracy: 0.575156\n",
      "INFO:root:Epoch: 18 [12736/40000 (32%)]\tLoss: 1.217869\tAccuracy: 0.577344\n",
      "INFO:root:Epoch: 18 [19136/40000 (48%)]\tLoss: 1.221238\tAccuracy: 0.563750\n",
      "INFO:root:Epoch: 18 [25536/40000 (64%)]\tLoss: 1.240920\tAccuracy: 0.556406\n",
      "INFO:root:Epoch: 18 [31936/40000 (80%)]\tLoss: 1.238185\tAccuracy: 0.556562\n",
      "INFO:root:Epoch: 18 [38336/40000 (96%)]\tLoss: 1.253230\tAccuracy: 0.559375\n",
      "INFO:root:Validation set: Average loss: 1.3626, Accuracy: 5175/10000 (52%)\n",
      "INFO:root:Epoch: 19 [6336/40000 (16%)]\tLoss: 1.179251\tAccuracy: 0.581719\n",
      "INFO:root:Epoch: 19 [12736/40000 (32%)]\tLoss: 1.223447\tAccuracy: 0.567969\n",
      "INFO:root:Epoch: 19 [19136/40000 (48%)]\tLoss: 1.212148\tAccuracy: 0.577812\n",
      "INFO:root:Epoch: 19 [25536/40000 (64%)]\tLoss: 1.237223\tAccuracy: 0.552031\n",
      "INFO:root:Epoch: 19 [31936/40000 (80%)]\tLoss: 1.245875\tAccuracy: 0.566094\n",
      "INFO:root:Epoch: 19 [38336/40000 (96%)]\tLoss: 1.244572\tAccuracy: 0.562969\n",
      "INFO:root:Validation set: Average loss: 1.3501, Accuracy: 5243/10000 (52%)\n",
      "INFO:root:Test set: Average loss: 1.3473, Accuracy: 5184/10000 (52%)\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "batch_size = 64\n",
    "dataset_loc = '/Users/saip/My Drive/machine-learning-fundamentals/datasets'\n",
    "train_loader, validation_loader, test_loader = load_data(dataset_loc, batch_size)\n",
    "model = FullyConnectedNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "for epoch in range(0,20):  # 10 epochs\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, validation_loader, epoch, validation=True)\n",
    "\n",
    "test(model, device, test_loader)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 20 [6336/40000 (16%)]\tLoss: 1.190246\tAccuracy: 0.573125\n",
      "INFO:root:Epoch: 20 [12736/40000 (32%)]\tLoss: 1.183392\tAccuracy: 0.581094\n",
      "INFO:root:Epoch: 20 [19136/40000 (48%)]\tLoss: 1.208495\tAccuracy: 0.569375\n",
      "INFO:root:Epoch: 20 [25536/40000 (64%)]\tLoss: 1.240068\tAccuracy: 0.557031\n",
      "INFO:root:Epoch: 20 [31936/40000 (80%)]\tLoss: 1.193498\tAccuracy: 0.582344\n",
      "INFO:root:Epoch: 20 [38336/40000 (96%)]\tLoss: 1.245668\tAccuracy: 0.565625\n",
      "INFO:root:Validation set: Average loss: 1.3892, Accuracy: 5134/10000 (51%)\n",
      "INFO:root:Epoch: 21 [6336/40000 (16%)]\tLoss: 1.167523\tAccuracy: 0.587812\n",
      "INFO:root:Epoch: 21 [12736/40000 (32%)]\tLoss: 1.206297\tAccuracy: 0.573438\n",
      "INFO:root:Epoch: 21 [19136/40000 (48%)]\tLoss: 1.229763\tAccuracy: 0.562813\n",
      "INFO:root:Epoch: 21 [25536/40000 (64%)]\tLoss: 1.213844\tAccuracy: 0.570312\n",
      "INFO:root:Epoch: 21 [31936/40000 (80%)]\tLoss: 1.218654\tAccuracy: 0.566719\n",
      "INFO:root:Epoch: 21 [38336/40000 (96%)]\tLoss: 1.251702\tAccuracy: 0.559063\n",
      "INFO:root:Validation set: Average loss: 1.3623, Accuracy: 5205/10000 (52%)\n",
      "INFO:root:Epoch: 22 [6336/40000 (16%)]\tLoss: 1.147145\tAccuracy: 0.594375\n",
      "INFO:root:Epoch: 22 [12736/40000 (32%)]\tLoss: 1.195580\tAccuracy: 0.574375\n",
      "INFO:root:Epoch: 22 [19136/40000 (48%)]\tLoss: 1.188405\tAccuracy: 0.580937\n",
      "INFO:root:Epoch: 22 [25536/40000 (64%)]\tLoss: 1.214308\tAccuracy: 0.573594\n",
      "INFO:root:Epoch: 22 [31936/40000 (80%)]\tLoss: 1.225131\tAccuracy: 0.565156\n",
      "INFO:root:Epoch: 22 [38336/40000 (96%)]\tLoss: 1.240099\tAccuracy: 0.557813\n",
      "INFO:root:Validation set: Average loss: 1.3533, Accuracy: 5305/10000 (53%)\n",
      "INFO:root:Epoch: 23 [6336/40000 (16%)]\tLoss: 1.155902\tAccuracy: 0.596562\n",
      "INFO:root:Epoch: 23 [12736/40000 (32%)]\tLoss: 1.179652\tAccuracy: 0.579844\n",
      "INFO:root:Epoch: 23 [19136/40000 (48%)]\tLoss: 1.201692\tAccuracy: 0.572500\n",
      "INFO:root:Epoch: 23 [25536/40000 (64%)]\tLoss: 1.215674\tAccuracy: 0.568125\n",
      "INFO:root:Epoch: 23 [31936/40000 (80%)]\tLoss: 1.199812\tAccuracy: 0.573594\n",
      "INFO:root:Epoch: 23 [38336/40000 (96%)]\tLoss: 1.221649\tAccuracy: 0.569844\n",
      "INFO:root:Validation set: Average loss: 1.3560, Accuracy: 5256/10000 (53%)\n",
      "INFO:root:Epoch: 24 [6336/40000 (16%)]\tLoss: 1.162979\tAccuracy: 0.598125\n",
      "INFO:root:Epoch: 24 [12736/40000 (32%)]\tLoss: 1.159804\tAccuracy: 0.586094\n",
      "INFO:root:Epoch: 24 [19136/40000 (48%)]\tLoss: 1.216297\tAccuracy: 0.570156\n",
      "INFO:root:Epoch: 24 [25536/40000 (64%)]\tLoss: 1.196181\tAccuracy: 0.575313\n",
      "INFO:root:Epoch: 24 [31936/40000 (80%)]\tLoss: 1.217273\tAccuracy: 0.562344\n",
      "INFO:root:Epoch: 24 [38336/40000 (96%)]\tLoss: 1.245516\tAccuracy: 0.556562\n",
      "INFO:root:Validation set: Average loss: 1.3261, Accuracy: 5318/10000 (53%)\n",
      "INFO:root:Epoch: 25 [6336/40000 (16%)]\tLoss: 1.146744\tAccuracy: 0.598437\n",
      "INFO:root:Epoch: 25 [12736/40000 (32%)]\tLoss: 1.176866\tAccuracy: 0.586562\n",
      "INFO:root:Epoch: 25 [19136/40000 (48%)]\tLoss: 1.204684\tAccuracy: 0.575781\n",
      "INFO:root:Epoch: 25 [25536/40000 (64%)]\tLoss: 1.188472\tAccuracy: 0.572344\n",
      "INFO:root:Epoch: 25 [31936/40000 (80%)]\tLoss: 1.202309\tAccuracy: 0.572187\n",
      "INFO:root:Epoch: 25 [38336/40000 (96%)]\tLoss: 1.200997\tAccuracy: 0.577812\n",
      "INFO:root:Validation set: Average loss: 1.3536, Accuracy: 5243/10000 (52%)\n",
      "INFO:root:Epoch: 26 [6336/40000 (16%)]\tLoss: 1.138106\tAccuracy: 0.592656\n",
      "INFO:root:Epoch: 26 [12736/40000 (32%)]\tLoss: 1.164671\tAccuracy: 0.585781\n",
      "INFO:root:Epoch: 26 [19136/40000 (48%)]\tLoss: 1.175736\tAccuracy: 0.587969\n",
      "INFO:root:Epoch: 26 [25536/40000 (64%)]\tLoss: 1.194037\tAccuracy: 0.580937\n",
      "INFO:root:Epoch: 26 [31936/40000 (80%)]\tLoss: 1.219864\tAccuracy: 0.564375\n",
      "INFO:root:Epoch: 26 [38336/40000 (96%)]\tLoss: 1.189655\tAccuracy: 0.578594\n",
      "INFO:root:Validation set: Average loss: 1.3657, Accuracy: 5283/10000 (53%)\n",
      "INFO:root:Epoch: 27 [6336/40000 (16%)]\tLoss: 1.160644\tAccuracy: 0.590000\n",
      "INFO:root:Epoch: 27 [12736/40000 (32%)]\tLoss: 1.158056\tAccuracy: 0.595000\n",
      "INFO:root:Epoch: 27 [19136/40000 (48%)]\tLoss: 1.192961\tAccuracy: 0.581094\n",
      "INFO:root:Epoch: 27 [25536/40000 (64%)]\tLoss: 1.195784\tAccuracy: 0.569844\n",
      "INFO:root:Epoch: 27 [31936/40000 (80%)]\tLoss: 1.195196\tAccuracy: 0.570781\n",
      "INFO:root:Epoch: 27 [38336/40000 (96%)]\tLoss: 1.207665\tAccuracy: 0.571250\n",
      "INFO:root:Validation set: Average loss: 1.3552, Accuracy: 5262/10000 (53%)\n",
      "INFO:root:Epoch: 28 [6336/40000 (16%)]\tLoss: 1.142785\tAccuracy: 0.595313\n",
      "INFO:root:Epoch: 28 [12736/40000 (32%)]\tLoss: 1.152277\tAccuracy: 0.597344\n",
      "INFO:root:Epoch: 28 [19136/40000 (48%)]\tLoss: 1.163961\tAccuracy: 0.587344\n",
      "INFO:root:Epoch: 28 [25536/40000 (64%)]\tLoss: 1.166379\tAccuracy: 0.587812\n",
      "INFO:root:Epoch: 28 [31936/40000 (80%)]\tLoss: 1.207832\tAccuracy: 0.572500\n",
      "INFO:root:Epoch: 28 [38336/40000 (96%)]\tLoss: 1.232017\tAccuracy: 0.567656\n",
      "INFO:root:Validation set: Average loss: 1.3619, Accuracy: 5218/10000 (52%)\n",
      "INFO:root:Epoch: 29 [6336/40000 (16%)]\tLoss: 1.118312\tAccuracy: 0.606094\n",
      "INFO:root:Epoch: 29 [12736/40000 (32%)]\tLoss: 1.158334\tAccuracy: 0.590469\n",
      "INFO:root:Epoch: 29 [19136/40000 (48%)]\tLoss: 1.184461\tAccuracy: 0.580937\n",
      "INFO:root:Epoch: 29 [25536/40000 (64%)]\tLoss: 1.198511\tAccuracy: 0.566562\n",
      "INFO:root:Epoch: 29 [31936/40000 (80%)]\tLoss: 1.183832\tAccuracy: 0.584844\n",
      "INFO:root:Epoch: 29 [38336/40000 (96%)]\tLoss: 1.183736\tAccuracy: 0.581094\n",
      "INFO:root:Validation set: Average loss: 1.3534, Accuracy: 5254/10000 (53%)\n",
      "INFO:root:Epoch: 30 [6336/40000 (16%)]\tLoss: 1.120115\tAccuracy: 0.606406\n",
      "INFO:root:Epoch: 30 [12736/40000 (32%)]\tLoss: 1.160932\tAccuracy: 0.594844\n",
      "INFO:root:Epoch: 30 [19136/40000 (48%)]\tLoss: 1.169850\tAccuracy: 0.589688\n",
      "INFO:root:Epoch: 30 [25536/40000 (64%)]\tLoss: 1.163722\tAccuracy: 0.590781\n",
      "INFO:root:Epoch: 30 [31936/40000 (80%)]\tLoss: 1.214450\tAccuracy: 0.568438\n",
      "INFO:root:Epoch: 30 [38336/40000 (96%)]\tLoss: 1.196097\tAccuracy: 0.574063\n",
      "INFO:root:Validation set: Average loss: 1.3373, Accuracy: 5278/10000 (53%)\n",
      "INFO:root:Epoch: 31 [6336/40000 (16%)]\tLoss: 1.142302\tAccuracy: 0.603281\n",
      "INFO:root:Epoch: 31 [12736/40000 (32%)]\tLoss: 1.119721\tAccuracy: 0.604844\n",
      "INFO:root:Epoch: 31 [19136/40000 (48%)]\tLoss: 1.164568\tAccuracy: 0.589844\n",
      "INFO:root:Epoch: 31 [25536/40000 (64%)]\tLoss: 1.178249\tAccuracy: 0.575469\n",
      "INFO:root:Epoch: 31 [31936/40000 (80%)]\tLoss: 1.177109\tAccuracy: 0.577031\n",
      "INFO:root:Epoch: 31 [38336/40000 (96%)]\tLoss: 1.200343\tAccuracy: 0.573125\n",
      "INFO:root:Validation set: Average loss: 1.3554, Accuracy: 5228/10000 (52%)\n",
      "INFO:root:Epoch: 32 [6336/40000 (16%)]\tLoss: 1.138633\tAccuracy: 0.597656\n",
      "INFO:root:Epoch: 32 [12736/40000 (32%)]\tLoss: 1.153714\tAccuracy: 0.590781\n",
      "INFO:root:Epoch: 32 [19136/40000 (48%)]\tLoss: 1.178184\tAccuracy: 0.585781\n",
      "INFO:root:Epoch: 32 [25536/40000 (64%)]\tLoss: 1.184573\tAccuracy: 0.576406\n",
      "INFO:root:Epoch: 32 [31936/40000 (80%)]\tLoss: 1.174178\tAccuracy: 0.580000\n",
      "INFO:root:Epoch: 32 [38336/40000 (96%)]\tLoss: 1.190010\tAccuracy: 0.576875\n",
      "INFO:root:Validation set: Average loss: 1.3540, Accuracy: 5253/10000 (53%)\n",
      "INFO:root:Epoch: 33 [6336/40000 (16%)]\tLoss: 1.097230\tAccuracy: 0.612031\n",
      "INFO:root:Epoch: 33 [12736/40000 (32%)]\tLoss: 1.155587\tAccuracy: 0.585000\n",
      "INFO:root:Epoch: 33 [19136/40000 (48%)]\tLoss: 1.153767\tAccuracy: 0.592500\n",
      "INFO:root:Epoch: 33 [25536/40000 (64%)]\tLoss: 1.156172\tAccuracy: 0.582969\n",
      "INFO:root:Epoch: 33 [31936/40000 (80%)]\tLoss: 1.174867\tAccuracy: 0.583594\n",
      "INFO:root:Epoch: 33 [38336/40000 (96%)]\tLoss: 1.184421\tAccuracy: 0.579063\n",
      "INFO:root:Validation set: Average loss: 1.3552, Accuracy: 5304/10000 (53%)\n",
      "INFO:root:Epoch: 34 [6336/40000 (16%)]\tLoss: 1.082310\tAccuracy: 0.617656\n",
      "INFO:root:Epoch: 34 [12736/40000 (32%)]\tLoss: 1.143322\tAccuracy: 0.596094\n",
      "INFO:root:Epoch: 34 [19136/40000 (48%)]\tLoss: 1.164161\tAccuracy: 0.594531\n",
      "INFO:root:Epoch: 34 [25536/40000 (64%)]\tLoss: 1.177114\tAccuracy: 0.586562\n",
      "INFO:root:Epoch: 34 [31936/40000 (80%)]\tLoss: 1.162742\tAccuracy: 0.586875\n",
      "INFO:root:Epoch: 34 [38336/40000 (96%)]\tLoss: 1.208123\tAccuracy: 0.577031\n",
      "INFO:root:Validation set: Average loss: 1.3791, Accuracy: 5186/10000 (52%)\n",
      "INFO:root:Epoch: 35 [6336/40000 (16%)]\tLoss: 1.109745\tAccuracy: 0.610156\n",
      "INFO:root:Epoch: 35 [12736/40000 (32%)]\tLoss: 1.140013\tAccuracy: 0.590469\n",
      "INFO:root:Epoch: 35 [19136/40000 (48%)]\tLoss: 1.160733\tAccuracy: 0.592344\n",
      "INFO:root:Epoch: 35 [25536/40000 (64%)]\tLoss: 1.168990\tAccuracy: 0.587812\n",
      "INFO:root:Epoch: 35 [31936/40000 (80%)]\tLoss: 1.174284\tAccuracy: 0.583438\n",
      "INFO:root:Epoch: 35 [38336/40000 (96%)]\tLoss: 1.170291\tAccuracy: 0.595625\n",
      "INFO:root:Validation set: Average loss: 1.3618, Accuracy: 5295/10000 (53%)\n",
      "INFO:root:Epoch: 36 [6336/40000 (16%)]\tLoss: 1.116801\tAccuracy: 0.611250\n",
      "INFO:root:Epoch: 36 [12736/40000 (32%)]\tLoss: 1.114781\tAccuracy: 0.608437\n",
      "INFO:root:Epoch: 36 [19136/40000 (48%)]\tLoss: 1.156202\tAccuracy: 0.594531\n",
      "INFO:root:Epoch: 36 [25536/40000 (64%)]\tLoss: 1.173833\tAccuracy: 0.576719\n",
      "INFO:root:Epoch: 36 [31936/40000 (80%)]\tLoss: 1.152477\tAccuracy: 0.588750\n",
      "INFO:root:Epoch: 36 [38336/40000 (96%)]\tLoss: 1.177876\tAccuracy: 0.579063\n",
      "INFO:root:Validation set: Average loss: 1.3425, Accuracy: 5329/10000 (53%)\n",
      "INFO:root:Epoch: 37 [6336/40000 (16%)]\tLoss: 1.112502\tAccuracy: 0.605625\n",
      "INFO:root:Epoch: 37 [12736/40000 (32%)]\tLoss: 1.128189\tAccuracy: 0.601406\n",
      "INFO:root:Epoch: 37 [19136/40000 (48%)]\tLoss: 1.159608\tAccuracy: 0.587969\n",
      "INFO:root:Epoch: 37 [25536/40000 (64%)]\tLoss: 1.122101\tAccuracy: 0.609375\n",
      "INFO:root:Epoch: 37 [31936/40000 (80%)]\tLoss: 1.181285\tAccuracy: 0.584063\n",
      "INFO:root:Epoch: 37 [38336/40000 (96%)]\tLoss: 1.164896\tAccuracy: 0.587812\n",
      "INFO:root:Validation set: Average loss: 1.3483, Accuracy: 5303/10000 (53%)\n",
      "INFO:root:Epoch: 38 [6336/40000 (16%)]\tLoss: 1.096884\tAccuracy: 0.615000\n",
      "INFO:root:Epoch: 38 [12736/40000 (32%)]\tLoss: 1.142617\tAccuracy: 0.593750\n",
      "INFO:root:Epoch: 38 [19136/40000 (48%)]\tLoss: 1.135057\tAccuracy: 0.598281\n",
      "INFO:root:Epoch: 38 [25536/40000 (64%)]\tLoss: 1.156936\tAccuracy: 0.596875\n",
      "INFO:root:Epoch: 38 [31936/40000 (80%)]\tLoss: 1.159784\tAccuracy: 0.589063\n",
      "INFO:root:Epoch: 38 [38336/40000 (96%)]\tLoss: 1.183319\tAccuracy: 0.578438\n",
      "INFO:root:Validation set: Average loss: 1.3671, Accuracy: 5238/10000 (52%)\n",
      "INFO:root:Epoch: 39 [6336/40000 (16%)]\tLoss: 1.092269\tAccuracy: 0.609688\n",
      "INFO:root:Epoch: 39 [12736/40000 (32%)]\tLoss: 1.127694\tAccuracy: 0.606406\n",
      "INFO:root:Epoch: 39 [19136/40000 (48%)]\tLoss: 1.161221\tAccuracy: 0.585781\n",
      "INFO:root:Epoch: 39 [25536/40000 (64%)]\tLoss: 1.145870\tAccuracy: 0.594219\n",
      "INFO:root:Epoch: 39 [31936/40000 (80%)]\tLoss: 1.141465\tAccuracy: 0.598281\n",
      "INFO:root:Epoch: 39 [38336/40000 (96%)]\tLoss: 1.151521\tAccuracy: 0.588906\n",
      "INFO:root:Validation set: Average loss: 1.3604, Accuracy: 5254/10000 (53%)\n",
      "INFO:root:Test set: Average loss: 1.3513, Accuracy: 5281/10000 (53%)\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/cifar10_experiment_11')\n",
    "for epoch in range(20,40):  # 10 epochs\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, validation_loader, epoch, validation=True)\n",
    "\n",
    "test(model, device, test_loader)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1 - 2 layers, lr=0.001,batch_size=64\n",
    "\n",
    "- Training accuracy for the model kept increasing till 90% but validation accuracy is just 50%. The state of the art stands at 99.5%\n",
    "- Similar trend with loss\n",
    "- The model is trying to learn the noise to decrease the training loss. \n",
    "- Does this mean the model is complex enough since the training accuracy reached 90%?\n",
    "\n",
    "v2 - 2 layers, lr=0.1, batch_size=64\n",
    "- Training accuracy and validationa accuracy stand ~40%, worst performance than before.\n",
    "- Maybe the lr is too high and the model is oscillating missing the local minima\n",
    "\n",
    "v3 - 2 layers, lr=0.1, batch_size=256\n",
    "- Increasing the batch_size did not have any effect. \n",
    "\n",
    "v4 - 4 layers, lr=0.001, batch_size=64\n",
    "- Did not have any effect. \n",
    "\n",
    "\n",
    "v5 - 4 layers, lr=0.01, batch_size=64\n",
    "- Worst performance. 15% accuracy in both training and validation\n",
    "\n",
    "v6 - 4 layers, lr=0.001, batch_size=64, batch_norm\n",
    "- Not a significant improvement, validation is still ~56%\n",
    "\n",
    "v6 - 4 layers, lr=0.005, batch_size=64, batch_norm\n",
    "- Effect of learning rate probably is minimal after applying batch norm\n",
    "\n",
    "v7 - 6 layers, lr=0.001, batch_size=64, batch_norm\n",
    "- Not a significant improvement. Validaiton accuracy stands at ~56% while training accuracy reaches 80%\n",
    "\n",
    "v7 - 6 layers, lr=0.001, batch_size=64, batch_norm, regularization\n",
    "- Same fate\n",
    "\n",
    "How do I know this is the maximum accuracy that I can get with this model? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
