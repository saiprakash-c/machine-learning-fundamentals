{"cells":[{"cell_type":"markdown","metadata":{"id":"Z55g0MR57BUQ"},"source":["##Goals\n","- Create a convolutional network for classifying CIFAR10 dataset\n","- Play with model architecture to achieve maximum accuracy\n","- Optimize hyperparameters to achieve maximum accuracy\n","- Use tensor board for visualiazing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13110,"status":"ok","timestamp":1703812211573,"user":{"displayName":"Sai P","userId":"15285502759182123980"},"user_tz":480},"id":"ByC8XGUz7BUS","outputId":"dbaefeca-341f-45e3-c1cc-1cdc5252bc71"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-30 21:48:46,644 - __main__ - INFO - Using cpu device\n","2023-12-30 21:48:46,644 - __main__ - INFO - Using cpu device\n"]}],"source":["# imports and setup\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import logging\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.tensorboard import SummaryWriter\n","from sklearn.model_selection import train_test_split\n","import time\n","\n","# Create a custom logger so that we don't affect the root logger\n","logger = logging.getLogger(__name__)\n","logger.setLevel(logging.INFO)\n","# stop propagating to the root logger to avoid duplicate logs\n","logger.propagate = False\n","\n","# Create stdout handler, we can create another handler to write to a file if needed\n","ch = logging.StreamHandler()\n","ch.setLevel(logging.INFO)\n","formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","ch.setFormatter(formatter)\n","\n","# Create a file handler\n","# use current time to create a unique log file name\n","\n","# Create a name for the experiment based on the current time and date\n","exp_name = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n","fh = logging.FileHandler(f'logs/{__name__}_{exp_name}.log')\n","fh.setLevel(logging.INFO)\n","fh.setFormatter(formatter)\n","\n","# add the handlers to the logger\n","logger.addHandler(ch)\n","logger.addHandler(fh)\n","\n","# create a tensorboard summary writer\n","writer = SummaryWriter('tensorboard_logs/' + exp_name)\n","\n","# Set random seed for pytorch and numpy\n","# numpy seed takes care of numpy and scipy\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","logger.info(f\"Using {device} device\")\n","\n","# classes from CIFAR10\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsQEOb2_1nir"},"outputs":[],"source":["# use a dictionary to store the hyperparameters\n","# this way we can easily pass them to the model and optimizer\n","\n","hyperparams = {\n","    'batch_size': 64,\n","    'num_epochs': 20,\n","    'learning_rate': 0.001,\n","    #'momentum': 0.9, # momentum is used to avoid local minima by taking into account the previous gradients\n","    #'weight_decay': 0.0001\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPpJE8te7BUT"},"outputs":[],"source":["# Data loading and preprocessing\n","def imshow(ax, img):\n","    npimg = img.numpy()\n","    # normalize the image from 0 to 1, cifar10 has it from -1 to 1\n","    npimg = (npimg+1)/2\n","    # imshow expects color channel to be the third dimension\n","    # and it expects the RGB values to be between\n","    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","def visualize_training_examples(train_dataset, classes, num_images=6):\n","    # Select num_images random indices\n","    indices = np.random.choice(len(train_dataset), size=num_images, replace=False)\n","\n","    # Show images and labels\n","    # figure size should be dependent on\n","    plt.figure(figsize=(8, (num_images//2)*4))\n","    for i, idx in enumerate(indices):\n","        ax = plt.subplot(num_images//2, 2, i + 1)\n","        image, label = train_dataset[idx]\n","        imshow(ax, image)\n","        ax.set_title(classes[label])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def load_data(dataset_loc='./data',batch_size=64):\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))  # Adjust these values for normalization\n","    ])\n","\n","    # Dataset class stores features and target\n","    # DataLoader builds an iterator on top of Dataset class\n","\n","    # Load CIFAR10 dataset\n","    train_dataset = datasets.CIFAR10(root=dataset_loc, train=True, download=True, transform=transform)\n","    test_dataset = datasets.CIFAR10(root=dataset_loc, train=False, download=True, transform=transform)\n","\n","    # Use stratified sampling to split the train dataset into train and validation\n","    train_dataset, validation_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42, stratify=train_dataset.targets)\n","\n","    # Log some info about the dataset type and size\n","    logger.info(f\"Train dataset size: {len(train_dataset)}\")\n","    logger.info(f\"Test dataset size: {len(test_dataset)}\")\n","\n","    # visualize_training_examples(train_dataset, classes, num_images=20)\n","\n","    # Data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, validation_loader, test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RqaDIcMM7BUU"},"outputs":[],"source":["class ConvolutionalNN(nn.Module):\n","    def __init__(self):\n","        super(ConvolutionalNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.conv4 = nn.Conv2d(128, 10, kernel_size=3, stride=1, padding=1)\n","        self.bn4 = nn.BatchNorm2d(10)\n","        self.fc1 = nn.Linear(10 * 8 * 8, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        # add average pooling layer to reduce the number of parameters\n","        x = F.relu(self.bn4(self.conv4(x)))\n","        x = F.avg_pool2d(x, 4)\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        x = self.fc1(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHGlp2Ud7BUU"},"outputs":[],"source":["def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # move data to device for every iteration\n","        # gpu memory is limited, so we can't move all data at once\n","        data, target = data.to(device), target.to(device)\n","        # zero the gradients, otherwise they will accumulate\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.cross_entropy(output, target)\n","        accuracy = (output.argmax(dim=1) == target).float().mean()\n","        # compute gradients\n","        loss.backward()\n","        # update weights\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        running_accuracy += accuracy.item()\n","        if (batch_idx+1) % 100 == 0: # +1 so that we don't print for 0th batch\n","            # Print running loss and running accuracy every 100 batches, also print fraction of epoch completed\n","            logger.info(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {running_loss/100:.6f}\\tAccuracy: {running_accuracy/100:.6f}')\n","            # logger.info(f'Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {running_loss:.6f}')\n","            # Log running loss to tensorboard\n","            writer.add_scalar('training loss', running_loss / 100, epoch * len(train_loader) + batch_idx)\n","            # Log accuracy to tensorboard\n","            writer.add_scalar('training accuracy', running_accuracy / 100, epoch * len(train_loader) + batch_idx)\n","            # writer.add_scalar('training accuracy', accuracy, epoch * len(train_loader) + batch_idx)\n","            running_loss = 0.0\n","            running_accuracy = 0.0\n","\n","def test(model, device, test_loader, epoch=None, validation=False):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            # reduction='sum' means that we will get the sum of the loss instead of the mean\n","            # item() gives the scalar value of the loss\n","            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","            # get the index of the max log-probability\n","            # dim=1 means that we will get the max value for each row\n","            pred = output.argmax(dim=1)\n","            correct += pred.eq(target).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    if validation:\n","        logger.info(f'Validation set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n","        writer.add_scalar('validation loss', test_loss, epoch)\n","        writer.add_scalar('validation accuracy', correct / len(test_loader.dataset), epoch)\n","    else:\n","        # log test loss and accuracy to tensorboard\n","        logger.info(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n","        writer.add_scalar('test loss', test_loss)\n","        writer.add_scalar('test accuracy', correct / len(test_loader.dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202902,"status":"ok","timestamp":1703812414470,"user":{"displayName":"Sai P","userId":"15285502759182123980"},"user_tz":480},"id":"mkkPM0un7BUU","outputId":"d659f61b-ff84-44b6-eb3d-644d5189b81a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-31 05:58:12,504 - __main__ - INFO - Train dataset size: 40000\n","2023-12-31 05:58:12,505 - __main__ - INFO - Test dataset size: 10000\n","2023-12-31 05:58:12,750 - __main__ - INFO - Model summary: \n","ConvolutionalNN(\n","  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn4): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=640, out_features=10, bias=True)\n",")\n","2023-12-31 05:58:12,755 - __main__ - INFO - Number of trainable parameters: 111656\n","2023-12-31 05:58:12,756 - __main__ - INFO - Hyperparameters: {'batch_size': 64, 'num_epochs': 20, 'learning_rate': 0.001}\n","2023-12-31 05:58:14,620 - __main__ - INFO - Epoch: 0 [6336/40000 (16%)]\tLoss: 1.748863\tAccuracy: 0.360469\n","2023-12-31 05:58:16,078 - __main__ - INFO - Epoch: 0 [12736/40000 (32%)]\tLoss: 1.409399\tAccuracy: 0.490938\n","2023-12-31 05:58:17,546 - __main__ - INFO - Epoch: 0 [19136/40000 (48%)]\tLoss: 1.298527\tAccuracy: 0.535312\n","2023-12-31 05:58:19,004 - __main__ - INFO - Epoch: 0 [25536/40000 (64%)]\tLoss: 1.228831\tAccuracy: 0.560312\n","2023-12-31 05:58:20,452 - __main__ - INFO - Epoch: 0 [31936/40000 (80%)]\tLoss: 1.151725\tAccuracy: 0.585313\n","2023-12-31 05:58:21,898 - __main__ - INFO - Epoch: 0 [38336/40000 (96%)]\tLoss: 1.134289\tAccuracy: 0.595781\n","2023-12-31 05:58:23,046 - __main__ - INFO - Validation set: Average loss: 1.0774, Accuracy: 6255/10000 (63%)\n","2023-12-31 05:58:24,497 - __main__ - INFO - Epoch: 1 [6336/40000 (16%)]\tLoss: 1.023722\tAccuracy: 0.635469\n","2023-12-31 05:58:25,948 - __main__ - INFO - Epoch: 1 [12736/40000 (32%)]\tLoss: 1.017137\tAccuracy: 0.642344\n","2023-12-31 05:58:27,393 - __main__ - INFO - Epoch: 1 [19136/40000 (48%)]\tLoss: 0.986963\tAccuracy: 0.654687\n","2023-12-31 05:58:28,859 - __main__ - INFO - Epoch: 1 [25536/40000 (64%)]\tLoss: 0.981721\tAccuracy: 0.655312\n","2023-12-31 05:58:30,332 - __main__ - INFO - Epoch: 1 [31936/40000 (80%)]\tLoss: 0.932907\tAccuracy: 0.671250\n","2023-12-31 05:58:31,801 - __main__ - INFO - Epoch: 1 [38336/40000 (96%)]\tLoss: 0.937750\tAccuracy: 0.672813\n","2023-12-31 05:58:32,945 - __main__ - INFO - Validation set: Average loss: 0.9304, Accuracy: 6726/10000 (67%)\n","2023-12-31 05:58:34,401 - __main__ - INFO - Epoch: 2 [6336/40000 (16%)]\tLoss: 0.869031\tAccuracy: 0.695781\n","2023-12-31 05:58:35,855 - __main__ - INFO - Epoch: 2 [12736/40000 (32%)]\tLoss: 0.854619\tAccuracy: 0.707969\n","2023-12-31 05:58:37,314 - __main__ - INFO - Epoch: 2 [19136/40000 (48%)]\tLoss: 0.873322\tAccuracy: 0.693750\n","2023-12-31 05:58:38,768 - __main__ - INFO - Epoch: 2 [25536/40000 (64%)]\tLoss: 0.879560\tAccuracy: 0.696719\n","2023-12-31 05:58:40,225 - __main__ - INFO - Epoch: 2 [31936/40000 (80%)]\tLoss: 0.855387\tAccuracy: 0.700156\n","2023-12-31 05:58:41,689 - __main__ - INFO - Epoch: 2 [38336/40000 (96%)]\tLoss: 0.829664\tAccuracy: 0.710938\n","2023-12-31 05:58:42,887 - __main__ - INFO - Validation set: Average loss: 0.8377, Accuracy: 7105/10000 (71%)\n","2023-12-31 05:58:44,368 - __main__ - INFO - Epoch: 3 [6336/40000 (16%)]\tLoss: 0.797643\tAccuracy: 0.721719\n","2023-12-31 05:58:45,831 - __main__ - INFO - Epoch: 3 [12736/40000 (32%)]\tLoss: 0.782735\tAccuracy: 0.727344\n","2023-12-31 05:58:47,288 - __main__ - INFO - Epoch: 3 [19136/40000 (48%)]\tLoss: 0.759793\tAccuracy: 0.741563\n","2023-12-31 05:58:48,746 - __main__ - INFO - Epoch: 3 [25536/40000 (64%)]\tLoss: 0.802299\tAccuracy: 0.722500\n","2023-12-31 05:58:50,204 - __main__ - INFO - Epoch: 3 [31936/40000 (80%)]\tLoss: 0.795559\tAccuracy: 0.717812\n","2023-12-31 05:58:51,665 - __main__ - INFO - Epoch: 3 [38336/40000 (96%)]\tLoss: 0.776688\tAccuracy: 0.723281\n","2023-12-31 05:58:52,809 - __main__ - INFO - Validation set: Average loss: 0.8243, Accuracy: 7126/10000 (71%)\n","2023-12-31 05:58:54,275 - __main__ - INFO - Epoch: 4 [6336/40000 (16%)]\tLoss: 0.716336\tAccuracy: 0.746406\n","2023-12-31 05:58:55,755 - __main__ - INFO - Epoch: 4 [12736/40000 (32%)]\tLoss: 0.719914\tAccuracy: 0.749375\n","2023-12-31 05:58:57,238 - __main__ - INFO - Epoch: 4 [19136/40000 (48%)]\tLoss: 0.738206\tAccuracy: 0.741250\n","2023-12-31 05:58:58,713 - __main__ - INFO - Epoch: 4 [25536/40000 (64%)]\tLoss: 0.721245\tAccuracy: 0.753594\n","2023-12-31 05:59:00,178 - __main__ - INFO - Epoch: 4 [31936/40000 (80%)]\tLoss: 0.774897\tAccuracy: 0.734688\n","2023-12-31 05:59:01,925 - __main__ - INFO - Epoch: 4 [38336/40000 (96%)]\tLoss: 0.742555\tAccuracy: 0.734531\n","2023-12-31 05:59:03,295 - __main__ - INFO - Validation set: Average loss: 0.8376, Accuracy: 7157/10000 (72%)\n","2023-12-31 05:59:04,767 - __main__ - INFO - Epoch: 5 [6336/40000 (16%)]\tLoss: 0.693110\tAccuracy: 0.761094\n","2023-12-31 05:59:06,233 - __main__ - INFO - Epoch: 5 [12736/40000 (32%)]\tLoss: 0.692609\tAccuracy: 0.758125\n","2023-12-31 05:59:07,702 - __main__ - INFO - Epoch: 5 [19136/40000 (48%)]\tLoss: 0.689680\tAccuracy: 0.759531\n","2023-12-31 05:59:09,192 - __main__ - INFO - Epoch: 5 [25536/40000 (64%)]\tLoss: 0.722200\tAccuracy: 0.748437\n","2023-12-31 05:59:10,680 - __main__ - INFO - Epoch: 5 [31936/40000 (80%)]\tLoss: 0.702108\tAccuracy: 0.760000\n","2023-12-31 05:59:12,160 - __main__ - INFO - Epoch: 5 [38336/40000 (96%)]\tLoss: 0.694306\tAccuracy: 0.760000\n","2023-12-31 05:59:13,311 - __main__ - INFO - Validation set: Average loss: 0.9217, Accuracy: 6937/10000 (69%)\n","2023-12-31 05:59:14,784 - __main__ - INFO - Epoch: 6 [6336/40000 (16%)]\tLoss: 0.651882\tAccuracy: 0.769062\n","2023-12-31 05:59:16,256 - __main__ - INFO - Epoch: 6 [12736/40000 (32%)]\tLoss: 0.657489\tAccuracy: 0.772344\n","2023-12-31 05:59:17,731 - __main__ - INFO - Epoch: 6 [19136/40000 (48%)]\tLoss: 0.687777\tAccuracy: 0.765000\n","2023-12-31 05:59:19,206 - __main__ - INFO - Epoch: 6 [25536/40000 (64%)]\tLoss: 0.664223\tAccuracy: 0.763281\n","2023-12-31 05:59:20,681 - __main__ - INFO - Epoch: 6 [31936/40000 (80%)]\tLoss: 0.662603\tAccuracy: 0.765781\n","2023-12-31 05:59:22,180 - __main__ - INFO - Epoch: 6 [38336/40000 (96%)]\tLoss: 0.660586\tAccuracy: 0.767500\n","2023-12-31 05:59:23,372 - __main__ - INFO - Validation set: Average loss: 0.7544, Accuracy: 7371/10000 (74%)\n","2023-12-31 05:59:24,863 - __main__ - INFO - Epoch: 7 [6336/40000 (16%)]\tLoss: 0.609175\tAccuracy: 0.791250\n","2023-12-31 05:59:26,342 - __main__ - INFO - Epoch: 7 [12736/40000 (32%)]\tLoss: 0.616140\tAccuracy: 0.788438\n","2023-12-31 05:59:27,820 - __main__ - INFO - Epoch: 7 [19136/40000 (48%)]\tLoss: 0.633055\tAccuracy: 0.779062\n","2023-12-31 05:59:29,303 - __main__ - INFO - Epoch: 7 [25536/40000 (64%)]\tLoss: 0.637287\tAccuracy: 0.778438\n","2023-12-31 05:59:30,782 - __main__ - INFO - Epoch: 7 [31936/40000 (80%)]\tLoss: 0.641361\tAccuracy: 0.771719\n","2023-12-31 05:59:32,262 - __main__ - INFO - Epoch: 7 [38336/40000 (96%)]\tLoss: 0.654263\tAccuracy: 0.772969\n","2023-12-31 05:59:33,419 - __main__ - INFO - Validation set: Average loss: 0.7600, Accuracy: 7441/10000 (74%)\n","2023-12-31 05:59:34,915 - __main__ - INFO - Epoch: 8 [6336/40000 (16%)]\tLoss: 0.605230\tAccuracy: 0.792188\n","2023-12-31 05:59:36,417 - __main__ - INFO - Epoch: 8 [12736/40000 (32%)]\tLoss: 0.593950\tAccuracy: 0.798125\n","2023-12-31 05:59:37,921 - __main__ - INFO - Epoch: 8 [19136/40000 (48%)]\tLoss: 0.617279\tAccuracy: 0.780937\n","2023-12-31 05:59:39,405 - __main__ - INFO - Epoch: 8 [25536/40000 (64%)]\tLoss: 0.618745\tAccuracy: 0.787344\n","2023-12-31 05:59:40,895 - __main__ - INFO - Epoch: 8 [31936/40000 (80%)]\tLoss: 0.618485\tAccuracy: 0.785312\n","2023-12-31 05:59:42,379 - __main__ - INFO - Epoch: 8 [38336/40000 (96%)]\tLoss: 0.597557\tAccuracy: 0.789219\n","2023-12-31 05:59:43,532 - __main__ - INFO - Validation set: Average loss: 0.7631, Accuracy: 7408/10000 (74%)\n","2023-12-31 05:59:45,019 - __main__ - INFO - Epoch: 9 [6336/40000 (16%)]\tLoss: 0.575457\tAccuracy: 0.795000\n","2023-12-31 05:59:46,505 - __main__ - INFO - Epoch: 9 [12736/40000 (32%)]\tLoss: 0.577908\tAccuracy: 0.798125\n","2023-12-31 05:59:48,005 - __main__ - INFO - Epoch: 9 [19136/40000 (48%)]\tLoss: 0.575366\tAccuracy: 0.803438\n","2023-12-31 05:59:49,520 - __main__ - INFO - Epoch: 9 [25536/40000 (64%)]\tLoss: 0.579943\tAccuracy: 0.796719\n","2023-12-31 05:59:51,019 - __main__ - INFO - Epoch: 9 [31936/40000 (80%)]\tLoss: 0.590324\tAccuracy: 0.797188\n","2023-12-31 05:59:52,509 - __main__ - INFO - Epoch: 9 [38336/40000 (96%)]\tLoss: 0.585169\tAccuracy: 0.794375\n","2023-12-31 05:59:53,668 - __main__ - INFO - Validation set: Average loss: 0.8197, Accuracy: 7351/10000 (74%)\n","2023-12-31 05:59:55,158 - __main__ - INFO - Epoch: 10 [6336/40000 (16%)]\tLoss: 0.523861\tAccuracy: 0.818125\n","2023-12-31 05:59:56,653 - __main__ - INFO - Epoch: 10 [12736/40000 (32%)]\tLoss: 0.522296\tAccuracy: 0.819219\n","2023-12-31 05:59:58,145 - __main__ - INFO - Epoch: 10 [19136/40000 (48%)]\tLoss: 0.559822\tAccuracy: 0.803750\n","2023-12-31 05:59:59,638 - __main__ - INFO - Epoch: 10 [25536/40000 (64%)]\tLoss: 0.562523\tAccuracy: 0.800000\n","2023-12-31 06:00:01,142 - __main__ - INFO - Epoch: 10 [31936/40000 (80%)]\tLoss: 0.553704\tAccuracy: 0.802656\n","2023-12-31 06:00:02,667 - __main__ - INFO - Epoch: 10 [38336/40000 (96%)]\tLoss: 0.588142\tAccuracy: 0.799531\n","2023-12-31 06:00:03,853 - __main__ - INFO - Validation set: Average loss: 0.7689, Accuracy: 7431/10000 (74%)\n","2023-12-31 06:00:05,351 - __main__ - INFO - Epoch: 11 [6336/40000 (16%)]\tLoss: 0.491934\tAccuracy: 0.828125\n","2023-12-31 06:00:06,846 - __main__ - INFO - Epoch: 11 [12736/40000 (32%)]\tLoss: 0.527783\tAccuracy: 0.817031\n","2023-12-31 06:00:08,347 - __main__ - INFO - Epoch: 11 [19136/40000 (48%)]\tLoss: 0.527109\tAccuracy: 0.816719\n","2023-12-31 06:00:09,848 - __main__ - INFO - Epoch: 11 [25536/40000 (64%)]\tLoss: 0.539370\tAccuracy: 0.808438\n","2023-12-31 06:00:11,342 - __main__ - INFO - Epoch: 11 [31936/40000 (80%)]\tLoss: 0.545523\tAccuracy: 0.810781\n","2023-12-31 06:00:12,842 - __main__ - INFO - Epoch: 11 [38336/40000 (96%)]\tLoss: 0.534698\tAccuracy: 0.820937\n","2023-12-31 06:00:14,021 - __main__ - INFO - Validation set: Average loss: 0.8172, Accuracy: 7282/10000 (73%)\n","2023-12-31 06:00:15,545 - __main__ - INFO - Epoch: 12 [6336/40000 (16%)]\tLoss: 0.471548\tAccuracy: 0.837500\n","2023-12-31 06:00:17,064 - __main__ - INFO - Epoch: 12 [12736/40000 (32%)]\tLoss: 0.485156\tAccuracy: 0.828438\n","2023-12-31 06:00:18,565 - __main__ - INFO - Epoch: 12 [19136/40000 (48%)]\tLoss: 0.495969\tAccuracy: 0.825937\n","2023-12-31 06:00:20,075 - __main__ - INFO - Epoch: 12 [25536/40000 (64%)]\tLoss: 0.517688\tAccuracy: 0.822500\n","2023-12-31 06:00:21,581 - __main__ - INFO - Epoch: 12 [31936/40000 (80%)]\tLoss: 0.536483\tAccuracy: 0.814688\n","2023-12-31 06:00:23,090 - __main__ - INFO - Epoch: 12 [38336/40000 (96%)]\tLoss: 0.518060\tAccuracy: 0.814375\n","2023-12-31 06:00:24,259 - __main__ - INFO - Validation set: Average loss: 0.7493, Accuracy: 7569/10000 (76%)\n","2023-12-31 06:00:25,763 - __main__ - INFO - Epoch: 13 [6336/40000 (16%)]\tLoss: 0.484313\tAccuracy: 0.833750\n","2023-12-31 06:00:27,276 - __main__ - INFO - Epoch: 13 [12736/40000 (32%)]\tLoss: 0.456923\tAccuracy: 0.840469\n","2023-12-31 06:00:28,797 - __main__ - INFO - Epoch: 13 [19136/40000 (48%)]\tLoss: 0.471235\tAccuracy: 0.828125\n","2023-12-31 06:00:30,320 - __main__ - INFO - Epoch: 13 [25536/40000 (64%)]\tLoss: 0.492065\tAccuracy: 0.832344\n","2023-12-31 06:00:31,829 - __main__ - INFO - Epoch: 13 [31936/40000 (80%)]\tLoss: 0.473614\tAccuracy: 0.838750\n","2023-12-31 06:00:33,338 - __main__ - INFO - Epoch: 13 [38336/40000 (96%)]\tLoss: 0.524995\tAccuracy: 0.814531\n","2023-12-31 06:00:34,510 - __main__ - INFO - Validation set: Average loss: 0.7208, Accuracy: 7617/10000 (76%)\n","2023-12-31 06:00:36,024 - __main__ - INFO - Epoch: 14 [6336/40000 (16%)]\tLoss: 0.454337\tAccuracy: 0.840156\n","2023-12-31 06:00:37,542 - __main__ - INFO - Epoch: 14 [12736/40000 (32%)]\tLoss: 0.468294\tAccuracy: 0.836094\n","2023-12-31 06:00:39,060 - __main__ - INFO - Epoch: 14 [19136/40000 (48%)]\tLoss: 0.460229\tAccuracy: 0.837656\n","2023-12-31 06:00:40,584 - __main__ - INFO - Epoch: 14 [25536/40000 (64%)]\tLoss: 0.457377\tAccuracy: 0.837344\n","2023-12-31 06:00:42,113 - __main__ - INFO - Epoch: 14 [31936/40000 (80%)]\tLoss: 0.481641\tAccuracy: 0.831719\n","2023-12-31 06:00:43,645 - __main__ - INFO - Epoch: 14 [38336/40000 (96%)]\tLoss: 0.482435\tAccuracy: 0.835938\n","2023-12-31 06:00:44,824 - __main__ - INFO - Validation set: Average loss: 0.7074, Accuracy: 7634/10000 (76%)\n","2023-12-31 06:00:46,338 - __main__ - INFO - Epoch: 15 [6336/40000 (16%)]\tLoss: 0.433244\tAccuracy: 0.846719\n","2023-12-31 06:00:47,854 - __main__ - INFO - Epoch: 15 [12736/40000 (32%)]\tLoss: 0.436618\tAccuracy: 0.848281\n","2023-12-31 06:00:49,372 - __main__ - INFO - Epoch: 15 [19136/40000 (48%)]\tLoss: 0.445140\tAccuracy: 0.843281\n","2023-12-31 06:00:50,893 - __main__ - INFO - Epoch: 15 [25536/40000 (64%)]\tLoss: 0.448794\tAccuracy: 0.841406\n","2023-12-31 06:00:52,409 - __main__ - INFO - Epoch: 15 [31936/40000 (80%)]\tLoss: 0.463524\tAccuracy: 0.839531\n","2023-12-31 06:00:53,942 - __main__ - INFO - Epoch: 15 [38336/40000 (96%)]\tLoss: 0.461393\tAccuracy: 0.840469\n","2023-12-31 06:00:55,150 - __main__ - INFO - Validation set: Average loss: 0.7100, Accuracy: 7678/10000 (77%)\n","2023-12-31 06:00:56,684 - __main__ - INFO - Epoch: 16 [6336/40000 (16%)]\tLoss: 0.391761\tAccuracy: 0.866875\n","2023-12-31 06:00:58,201 - __main__ - INFO - Epoch: 16 [12736/40000 (32%)]\tLoss: 0.428092\tAccuracy: 0.849375\n","2023-12-31 06:00:59,722 - __main__ - INFO - Epoch: 16 [19136/40000 (48%)]\tLoss: 0.421074\tAccuracy: 0.851719\n","2023-12-31 06:01:01,243 - __main__ - INFO - Epoch: 16 [25536/40000 (64%)]\tLoss: 0.460266\tAccuracy: 0.840625\n","2023-12-31 06:01:02,764 - __main__ - INFO - Epoch: 16 [31936/40000 (80%)]\tLoss: 0.421597\tAccuracy: 0.852969\n","2023-12-31 06:01:04,287 - __main__ - INFO - Epoch: 16 [38336/40000 (96%)]\tLoss: 0.457532\tAccuracy: 0.839375\n","2023-12-31 06:01:05,465 - __main__ - INFO - Validation set: Average loss: 0.7647, Accuracy: 7552/10000 (76%)\n","2023-12-31 06:01:06,998 - __main__ - INFO - Epoch: 17 [6336/40000 (16%)]\tLoss: 0.375637\tAccuracy: 0.870938\n","2023-12-31 06:01:08,536 - __main__ - INFO - Epoch: 17 [12736/40000 (32%)]\tLoss: 0.391281\tAccuracy: 0.863125\n","2023-12-31 06:01:10,074 - __main__ - INFO - Epoch: 17 [19136/40000 (48%)]\tLoss: 0.404069\tAccuracy: 0.859219\n","2023-12-31 06:01:11,593 - __main__ - INFO - Epoch: 17 [25536/40000 (64%)]\tLoss: 0.407676\tAccuracy: 0.857187\n","2023-12-31 06:01:13,110 - __main__ - INFO - Epoch: 17 [31936/40000 (80%)]\tLoss: 0.438269\tAccuracy: 0.844219\n","2023-12-31 06:01:14,631 - __main__ - INFO - Epoch: 17 [38336/40000 (96%)]\tLoss: 0.430062\tAccuracy: 0.846406\n","2023-12-31 06:01:15,808 - __main__ - INFO - Validation set: Average loss: 0.7204, Accuracy: 7678/10000 (77%)\n","2023-12-31 06:01:17,327 - __main__ - INFO - Epoch: 18 [6336/40000 (16%)]\tLoss: 0.359661\tAccuracy: 0.876250\n","2023-12-31 06:01:18,845 - __main__ - INFO - Epoch: 18 [12736/40000 (32%)]\tLoss: 0.382043\tAccuracy: 0.858281\n","2023-12-31 06:01:20,374 - __main__ - INFO - Epoch: 18 [19136/40000 (48%)]\tLoss: 0.395201\tAccuracy: 0.861719\n","2023-12-31 06:01:21,908 - __main__ - INFO - Epoch: 18 [25536/40000 (64%)]\tLoss: 0.400713\tAccuracy: 0.861563\n","2023-12-31 06:01:23,435 - __main__ - INFO - Epoch: 18 [31936/40000 (80%)]\tLoss: 0.405725\tAccuracy: 0.858437\n","2023-12-31 06:01:24,953 - __main__ - INFO - Epoch: 18 [38336/40000 (96%)]\tLoss: 0.412215\tAccuracy: 0.855469\n","2023-12-31 06:01:26,127 - __main__ - INFO - Validation set: Average loss: 0.7745, Accuracy: 7542/10000 (75%)\n","2023-12-31 06:01:27,645 - __main__ - INFO - Epoch: 19 [6336/40000 (16%)]\tLoss: 0.333502\tAccuracy: 0.883594\n","2023-12-31 06:01:29,166 - __main__ - INFO - Epoch: 19 [12736/40000 (32%)]\tLoss: 0.352424\tAccuracy: 0.876094\n","2023-12-31 06:01:30,680 - __main__ - INFO - Epoch: 19 [19136/40000 (48%)]\tLoss: 0.363900\tAccuracy: 0.872969\n","2023-12-31 06:01:32,199 - __main__ - INFO - Epoch: 19 [25536/40000 (64%)]\tLoss: 0.390946\tAccuracy: 0.861563\n","2023-12-31 06:01:33,724 - __main__ - INFO - Epoch: 19 [31936/40000 (80%)]\tLoss: 0.384744\tAccuracy: 0.867031\n","2023-12-31 06:01:35,260 - __main__ - INFO - Epoch: 19 [38336/40000 (96%)]\tLoss: 0.408224\tAccuracy: 0.855938\n","2023-12-31 06:01:36,442 - __main__ - INFO - Validation set: Average loss: 0.7841, Accuracy: 7545/10000 (75%)\n","2023-12-31 06:01:39,476 - __main__ - INFO - Test set: Average loss: 0.8032, Accuracy: 7454/10000 (75%)\n"]}],"source":["# Main execution\n","dataset_loc = '/Users/saip/My Drive/machine-learning-fundamentals/datasets'\n","train_loader, validation_loader, test_loader = load_data(dataset_loc, hyperparams['batch_size'])\n","model = ConvolutionalNN().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n","# print the model summary along with the number of trainable parameters\n","logger.info(\"Model summary: \\n\" + str(model))\n","# print the number of trainable parameters\n","logger.info(f\"Number of trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n","\n","# print the hyperparameters\n","logger.info(f\"Hyperparameters: {hyperparams}\")\n","\n","for epoch in range(0, hyperparams['num_epochs']):  # 20 epochs\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, validation_loader, epoch, validation=True)\n","\n","test(model, device, test_loader)\n","writer.close()\n"]},{"cell_type":"markdown","metadata":{"id":"-G9c1tzL1nis"},"source":["Achieved a maximum validaiton accuracy of 77%."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}